{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "2ca79484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies and setup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as matplotlib\n",
    "import matplotlib.dates as matplotlibdates\n",
    "from matplotlib.dates import date2num\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "0db662c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read individual csv files and store as DataFrames\n",
    "\n",
    "atkinson_path = \"Resources/dam_levels/atkinson.csv\"\n",
    "atkinson_df = pd.read_csv(atkinson_path)\n",
    "\n",
    "baroon_pocket_path = \"Resources/dam_levels/baroon_pocket.csv\"\n",
    "baroon_pocket_df = pd.read_csv(baroon_pocket_path)\n",
    "\n",
    "bill_gunn_path = \"Resources/dam_levels/bill_gunn.csv\"\n",
    "bill_gunn_df = pd.read_csv(bill_gunn_path)\n",
    "\n",
    "borumba_path = \"Resources/dam_levels/borumba.csv\"\n",
    "borumba_df = pd.read_csv(borumba_path)\n",
    "\n",
    "cedar_pocket_path = \"Resources/dam_levels/cedar_pocket.csv\"\n",
    "cedar_pocket_df = pd.read_csv(cedar_pocket_path)\n",
    "\n",
    "clarendon_path = \"Resources/dam_levels/clarendon.csv\"\n",
    "clarendon_df = pd.read_csv(clarendon_path)\n",
    "\n",
    "cooloolabin_path = \"Resources/dam_levels/cooloolabin.csv\"\n",
    "cooloolabin_df = pd.read_csv(cooloolabin_path)\n",
    "\n",
    "enoggera_path = \"Resources/dam_levels/enoggera.csv\"\n",
    "enoggera_df = pd.read_csv(enoggera_path)\n",
    "\n",
    "ewen_maddock_path = \"Resources/dam_levels/ewen_maddock.csv\"\n",
    "ewen_maddock_df = pd.read_csv(ewen_maddock_path)\n",
    "\n",
    "gold_creek_path = \"Resources/dam_levels/gold_creek.csv\"\n",
    "gold_creek_df = pd.read_csv(gold_creek_path)\n",
    "\n",
    "hinze_path = \"Resources/dam_levels/hinze.csv\"\n",
    "hinze_df = pd.read_csv(hinze_path)\n",
    "\n",
    "lake_kurwongbah_path = \"Resources/dam_levels/lake_kurwongbah.csv\"\n",
    "lake_kurwongbah_df = pd.read_csv(lake_kurwongbah_path)\n",
    "\n",
    "lake_macdonald_path = \"Resources/dam_levels/lake_macdonald.csv\"\n",
    "lake_macdonald_df = pd.read_csv(lake_macdonald_path)\n",
    "\n",
    "lake_manchester_path = \"Resources/dam_levels/lake_manchester.csv\"\n",
    "lake_manchester_df = pd.read_csv(lake_manchester_path)\n",
    "\n",
    "leslie_harrison_path = \"Resources/dam_levels/leslie_harrison.csv\"\n",
    "leslie_harrison_df = pd.read_csv(leslie_harrison_path)\n",
    "\n",
    "little_nerang_path = \"Resources/dam_levels/little_nerang.csv\"\n",
    "little_nerang_df = pd.read_csv(little_nerang_path)\n",
    "\n",
    "maroon_path = \"Resources/dam_levels/maroon.csv\"\n",
    "maroon_df = pd.read_csv(maroon_path)\n",
    "\n",
    "nindooinbah_path = \"Resources/dam_levels/nindooinbah.csv\"\n",
    "nindooinbah_df = pd.read_csv(nindooinbah_path)\n",
    "\n",
    "north_pine_path = \"Resources/dam_levels/north_pine.csv\"\n",
    "north_pine_df = pd.read_csv(north_pine_path)\n",
    "\n",
    "poona_path = \"Resources/dam_levels/poona.csv\"\n",
    "poona_df = pd.read_csv(poona_path)\n",
    "\n",
    "seq_water_grid_path = \"Resources/dam_levels/seq_water_grid.csv\"\n",
    "seq_water_grid_df = pd.read_csv(seq_water_grid_path)\n",
    "\n",
    "somerset_path = \"Resources/dam_levels/somerset.csv\"\n",
    "somerset_df = pd.read_csv(somerset_path)\n",
    "\n",
    "wappa_path = \"Resources/dam_levels/wappa.csv\"\n",
    "wappa_df = pd.read_csv(wappa_path)\n",
    "\n",
    "wivenhoe_path = \"Resources/dam_levels/wivenhoe.csv\"\n",
    "wivenhoe_df = pd.read_csv(wivenhoe_path)\n",
    "\n",
    "wyaralong_path = \"Resources/dam_levels/wyaralong.csv\"\n",
    "wyaralong_df = pd.read_csv(wyaralong_path)\n",
    "\n",
    "alderley_rainfall_path = \"Resources/rainfall/alderley_rainfall.csv\"\n",
    "alderley_df = pd.read_csv(alderley_rainfall_path)\n",
    "\n",
    "brisbane_rainfall_path = \"Resources/rainfall/brisbane_rainfall.csv\"\n",
    "brisbane_df = pd.read_csv(brisbane_rainfall_path)\n",
    "\n",
    "dam_locations_path = \"Resources/dam_locations.csv\"\n",
    "dam_locations_df = pd.read_csv(dam_locations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "99bd09a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Last Observation (%)</th>\n",
       "      <th>Last Observation (ML)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>4/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>5/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>6/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>7/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>8/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>28-02-2022</td>\n",
       "      <td>112.4</td>\n",
       "      <td>115681.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>01-03-2022</td>\n",
       "      <td>105.5</td>\n",
       "      <td>108555.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>02-03-2022</td>\n",
       "      <td>103.1</td>\n",
       "      <td>106093.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>03-03-2022</td>\n",
       "      <td>105.8</td>\n",
       "      <td>108820.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>04-03-2022</td>\n",
       "      <td>105.3</td>\n",
       "      <td>108316.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41985 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name        Date  Last Observation (%)  Last Observation (ML)\n",
       "0      Atkinson     4/03/17                   5.4                1655.39\n",
       "1      Atkinson     5/03/17                   5.4                1655.39\n",
       "2      Atkinson     6/03/17                   5.4                1655.39\n",
       "3      Atkinson     7/03/17                   5.4                1655.39\n",
       "4      Atkinson     8/03/17                   5.4                1655.39\n",
       "...         ...         ...                   ...                    ...\n",
       "1822  Wyaralong  28-02-2022                 112.4              115681.40\n",
       "1823  Wyaralong  01-03-2022                 105.5              108555.70\n",
       "1824  Wyaralong  02-03-2022                 103.1              106093.79\n",
       "1825  Wyaralong  03-03-2022                 105.8              108820.61\n",
       "1826  Wyaralong  04-03-2022                 105.3              108316.44\n",
       "\n",
       "[41985 rows x 4 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge csvs and store as a DataFrame\n",
    "\n",
    "dam_frames = [atkinson_df, baroon_pocket_df, cedar_pocket_df, clarendon_df, cooloolabin_df,\n",
    "                          enoggera_df, ewen_maddock_df, gold_creek_df, hinze_df, lake_kurwongbah_df,\n",
    "                          lake_macdonald_df, lake_manchester_df, leslie_harrison_df, little_nerang_df,\n",
    "                          maroon_df, nindooinbah_df, north_pine_df, poona_df, seq_water_grid_df, somerset_df,\n",
    "                          wappa_df, wivenhoe_df, wyaralong_df]\n",
    "merged_dam_df = pd.concat(dam_frames)\n",
    "merged_dam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "97bdf2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Last Observation (%)</th>\n",
       "      <th>Last Observation (ML)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>4/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>5/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>6/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>7/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>8/03/17</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>28/02/22</td>\n",
       "      <td>107.5</td>\n",
       "      <td>32686.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>1/03/22</td>\n",
       "      <td>104.1</td>\n",
       "      <td>31656.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2/03/22</td>\n",
       "      <td>102.7</td>\n",
       "      <td>31223.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>3/03/22</td>\n",
       "      <td>103.0</td>\n",
       "      <td>31324.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>4/03/22</td>\n",
       "      <td>102.4</td>\n",
       "      <td>31117.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1821 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name      Date  Last Observation (%)  Last Observation (ML)\n",
       "0     Atkinson   4/03/17                   5.4                1655.39\n",
       "1     Atkinson   5/03/17                   5.4                1655.39\n",
       "2     Atkinson   6/03/17                   5.4                1655.39\n",
       "3     Atkinson   7/03/17                   5.4                1655.39\n",
       "4     Atkinson   8/03/17                   5.4                1655.39\n",
       "...        ...       ...                   ...                    ...\n",
       "1816  Atkinson  28/02/22                 107.5               32686.23\n",
       "1817  Atkinson   1/03/22                 104.1               31656.60\n",
       "1818  Atkinson   2/03/22                 102.7               31223.76\n",
       "1819  Atkinson   3/03/22                 103.0               31324.52\n",
       "1820  Atkinson   4/03/22                 102.4               31117.77\n",
       "\n",
       "[1821 rows x 4 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define each dam name from 'Name' column\n",
    "\n",
    "atkinson_df = merged_dam_df[merged_dam_df.Name == 'Atkinson']\n",
    "baroon_pocket_df = merged_dam_df[merged_dam_df.Name == 'Baroon Pocket']\n",
    "cedar_pocket_df = merged_dam_df[merged_dam_df.Name == 'Cedar Pocket']\n",
    "clarendon_df = merged_dam_df[merged_dam_df.Name == 'Clarendon']\n",
    "cooloolabin_df = merged_dam_df[merged_dam_df.Name == 'Cooloolabin']\n",
    "enoggera_df = merged_dam_df[merged_dam_df.Name == 'Enoggera']\n",
    "ewen_maddock_df = merged_dam_df[merged_dam_df.Name == 'Ewen Maddock']\n",
    "gold_creek_df = merged_dam_df[merged_dam_df.Name == 'Gold Creek']\n",
    "hinze_df = merged_dam_df[merged_dam_df.Name == 'Hinze']\n",
    "lake_kurwongbah_df = merged_dam_df[merged_dam_df.Name == 'Lake Kurwongbah']\n",
    "lake_macdonald_df = merged_dam_df[merged_dam_df.Name == 'Lake Macdonald']\n",
    "lake_manchester_df = merged_dam_df[merged_dam_df.Name == 'Lake Manchester']\n",
    "leslie_harrison_df = merged_dam_df[merged_dam_df.Name == 'Leslie Harrison']\n",
    "little_nerang_df = merged_dam_df[merged_dam_df.Name == 'Little Nerang']\n",
    "maroon_df = merged_dam_df[merged_dam_df.Name == 'Maroon']\n",
    "nindooinbah_df = merged_dam_df[merged_dam_df.Name == 'Nindooinbah']\n",
    "north_pine_df = merged_dam_df[merged_dam_df.Name == 'North Pine']\n",
    "poona_df = merged_dam_df[merged_dam_df.Name == 'Poona']\n",
    "seq_water_grid_df = merged_dam_df[merged_dam_df.Name == 'SEQ Water Grid']\n",
    "somerset_df = merged_dam_df[merged_dam_df.Name == 'Somerset']\n",
    "wappa_df = merged_dam_df[merged_dam_df.Name == 'Wappa']\n",
    "wivenhoe_df = merged_dam_df[merged_dam_df.Name == 'Wivenhoe']\n",
    "wyaralong_df = merged_dam_df[merged_dam_df.Name == 'Wyaralong']\n",
    "\n",
    "atkinson_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "28e178d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Last Observation (%)</th>\n",
       "      <th>Last Observation (ML)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-04-03</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-06-03</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Atkinson</td>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1655.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>112.4</td>\n",
       "      <td>115681.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>105.5</td>\n",
       "      <td>108555.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>2022-02-03</td>\n",
       "      <td>103.1</td>\n",
       "      <td>106093.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>105.8</td>\n",
       "      <td>108820.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>Wyaralong</td>\n",
       "      <td>2022-04-03</td>\n",
       "      <td>105.3</td>\n",
       "      <td>108316.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41985 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name       Date  Last Observation (%)  Last Observation (ML)\n",
       "0      Atkinson 2017-04-03                   5.4                1655.39\n",
       "1      Atkinson 2017-05-03                   5.4                1655.39\n",
       "2      Atkinson 2017-06-03                   5.4                1655.39\n",
       "3      Atkinson 2017-07-03                   5.4                1655.39\n",
       "4      Atkinson 2017-08-03                   5.4                1655.39\n",
       "...         ...        ...                   ...                    ...\n",
       "1822  Wyaralong 2022-02-28                 112.4              115681.40\n",
       "1823  Wyaralong 2022-01-03                 105.5              108555.70\n",
       "1824  Wyaralong 2022-02-03                 103.1              106093.79\n",
       "1825  Wyaralong 2022-03-03                 105.8              108820.61\n",
       "1826  Wyaralong 2022-04-03                 105.3              108316.44\n",
       "\n",
       "[41985 rows x 4 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'Date' columns in all .csvs to datetime\n",
    "\n",
    "merged_dam_df['Date'] = pd.to_datetime(merged_dam_df['Date'])\n",
    "merged_dam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4e5abf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4296619.85"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total 'Last Observation (ML)' for each dam\n",
    "\n",
    "atkinson_total_ML = atkinson_df['Last Observation (ML)'].sum()\n",
    "baroon_pocket_total_ML = baroon_pocket_df['Last Observation (ML)'].sum()\n",
    "cedar_pocket_total_ML = cedar_pocket_df['Last Observation (ML)'].sum()\n",
    "clarendon_total_ML = clarendon_df['Last Observation (ML)'].sum()\n",
    "cooloolabin_total_ML = cooloolabin_df['Last Observation (ML)'].sum()\n",
    "enoggera_total_ML = enoggera_df['Last Observation (ML)'].sum()\n",
    "ewen_maddock_total_ML = ewen_maddock_df['Last Observation (ML)'].sum()\n",
    "gold_creek_total_ML = gold_creek_df['Last Observation (ML)'].sum()\n",
    "hinze_total_ML = hinze_df['Last Observation (ML)'].sum()\n",
    "lake_kurwongbah_total_ML = lake_kurwongbah_df['Last Observation (ML)'].sum()\n",
    "lake_macdonald_total_ML = lake_macdonald_df['Last Observation (ML)'].sum()\n",
    "lake_manchester_total_ML = lake_manchester_df['Last Observation (ML)'].sum()\n",
    "leslie_harrison_total_ML = leslie_harrison_df['Last Observation (ML)'].sum()\n",
    "little_nerang_total_ML = little_nerang_df['Last Observation (ML)'].sum()\n",
    "maroon_total_ML = maroon_df['Last Observation (ML)'].sum()\n",
    "nindooinbah_total_ML = nindooinbah_df['Last Observation (ML)'].sum()\n",
    "north_pine_total_ML = north_pine_df['Last Observation (ML)'].sum()\n",
    "poona_total_ML = poona_df['Last Observation (ML)'].sum()\n",
    "seq_water_grid_total_ML = seq_water_grid_df['Last Observation (ML)'].sum()\n",
    "somerset_total_ML = somerset_df['Last Observation (ML)'].sum()\n",
    "wappa_total_ML = wappa_df['Last Observation (ML)'].sum()\n",
    "wivenhoe_total_ML = wivenhoe_df['Last Observation (ML)'].sum()\n",
    "wyaralong_total_ML = wyaralong_df['Last Observation (ML)'].sum()\n",
    "\n",
    "atkinson_total_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "8d1be1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142685.1639442659"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average of 'Last Observation (ML)' for each dam + total (merged_dam_df)\n",
    "\n",
    "merged_avg_ML = merged_dam_df['Last Observation (ML)'].mean()\n",
    "\n",
    "atkinson_avg_ML = atkinson_df['Last Observation (ML)'].mean()\n",
    "baroon_pocket_avg_ML = baroon_pocket_df['Last Observation (ML)'].mean()\n",
    "cedar_pocket_avg_ML = cedar_pocket_df['Last Observation (ML)'].mean()\n",
    "clarendon_avg_ML = clarendon_df['Last Observation (ML)'].mean()\n",
    "cooloolabin_avg_ML = cooloolabin_df['Last Observation (ML)'].mean()\n",
    "enoggera_avg_ML = enoggera_df['Last Observation (ML)'].mean()\n",
    "ewen_maddock_avg_ML = ewen_maddock_df['Last Observation (ML)'].mean()\n",
    "gold_creek_avg_ML = gold_creek_df['Last Observation (ML)'].mean()\n",
    "hinze_avg_ML = hinze_df['Last Observation (ML)'].mean()\n",
    "lake_kurwongbah_avg_ML = lake_kurwongbah_df['Last Observation (ML)'].mean()\n",
    "lake_macdonald_avg_ML = lake_macdonald_df['Last Observation (ML)'].mean()\n",
    "lake_manchester_avg_ML = lake_manchester_df['Last Observation (ML)'].mean()\n",
    "leslie_harrison_avg_ML = leslie_harrison_df['Last Observation (ML)'].mean()\n",
    "little_nerang_avg_ML = little_nerang_df['Last Observation (ML)'].mean()\n",
    "maroon_avg_ML = maroon_df['Last Observation (ML)'].mean()\n",
    "nindooinbah_avg_ML = nindooinbah_df['Last Observation (ML)'].mean()\n",
    "north_pine_avg_ML = north_pine_df['Last Observation (ML)'].mean()\n",
    "poona_avg_ML = poona_df['Last Observation (ML)'].mean()\n",
    "seq_water_grid_avg_ML = seq_water_grid_df['Last Observation (ML)'].mean()\n",
    "somerset_avg_ML = somerset_df['Last Observation (ML)'].mean()\n",
    "wappa_avg_ML = wappa_df['Last Observation (ML)'].mean()\n",
    "wivenhoe_avg_ML = wivenhoe_df['Last Observation (ML)'].mean()\n",
    "wyaralong_avg_ML = wyaralong_df['Last Observation (ML)'].mean()\n",
    "\n",
    "merged_avg_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "e765b7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.98479695129198"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate average of 'Last Observation (%)' for each dam + total (merged_dam_df)\n",
    "\n",
    "merged_avg_percent = merged_dam_df['Last Observation (%)'].mean()\n",
    "\n",
    "atkinson_avg_percent = atkinson_df['Last Observation (%)'].mean()\n",
    "baroon_pocket_avg_percent = baroon_pocket_df['Last Observation (%)'].mean()\n",
    "cedar_pocket_avg_percent = cedar_pocket_df['Last Observation (%)'].mean()\n",
    "clarendon_avg_percent = clarendon_df['Last Observation (%)'].mean()\n",
    "cooloolabin_avg_percent = cooloolabin_df['Last Observation (%)'].mean()\n",
    "enoggera_avg_percent = enoggera_df['Last Observation (%)'].mean()\n",
    "ewen_maddock_avg_percent = ewen_maddock_df['Last Observation (%)'].mean()\n",
    "gold_creek_avg_percent = gold_creek_df['Last Observation (%)'].mean()\n",
    "hinze_avg_percent = hinze_df['Last Observation (%)'].mean()\n",
    "lake_kurwongbah_avg_percent = lake_kurwongbah_df['Last Observation (%)'].mean()\n",
    "lake_macdonald_avg_percent = lake_macdonald_df['Last Observation (%)'].mean()\n",
    "lake_manchester_avg_percent = lake_manchester_df['Last Observation (%)'].mean()\n",
    "leslie_harrison_avg_percent = leslie_harrison_df['Last Observation (%)'].mean()\n",
    "little_nerang_avg_percent = little_nerang_df['Last Observation (%)'].mean()\n",
    "maroon_avg_percent = maroon_df['Last Observation (%)'].mean()\n",
    "nindooinbah_avg_percent = nindooinbah_df['Last Observation (%)'].mean()\n",
    "north_pine_avg_percent = north_pine_df['Last Observation (%)'].mean()\n",
    "poona_avg_percent = poona_df['Last Observation (%)'].mean()\n",
    "seq_water_grid_avg_percent = seq_water_grid_df['Last Observation (%)'].mean()\n",
    "somerset_avg_percent = somerset_df['Last Observation (%)'].mean()\n",
    "wappa_avg_percent = wappa_df['Last Observation (%)'].mean()\n",
    "wivenhoe_avg_percent = wivenhoe_df['Last Observation (%)'].mean()\n",
    "wyaralong_avg_percent = wyaralong_df['Last Observation (%)'].mean()\n",
    "\n",
    "merged_avg_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "43744ab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-408-0d8ff3056dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmerged_dam_yearly_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_dam_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_dam_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0matkinson_yearly_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matkinson_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matkinson_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mbaroon_pocket_yearly_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaroon_pocket_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaroon_pocket_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcedar_pocket_yearly_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcedar_pocket_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcedar_pocket_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5459\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5460\u001b[0m         ):\n\u001b[0;32m-> 5461\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mPeriodProperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Group by year and calculate yearly totals\n",
    "\n",
    "merged_dam_yearly_df = merged_dam_df.groupby(merged_dam_df['Date'].dt.to_period('Y')).sum()\n",
    "\n",
    "atkinson_yearly_df = atkinson_df.groupby(atkinson_df['Date'].dt.to_period('Y')).sum()\n",
    "baroon_pocket_yearly_df = baroon_pocket_df.groupby(baroon_pocket_df['Date'].dt.to_period('Y')).sum()\n",
    "cedar_pocket_yearly_df = cedar_pocket_df.groupby(cedar_pocket_df['Date'].dt.to_period('Y')).sum()\n",
    "clarendon_yearly_df = clarendon_df.groupby(clarendon_df['Date'].dt.to_period('Y')).sum()\n",
    "cooloolabin_yearly_df = cooloolabin_df.groupby(cooloolabin_df['Date'].dt.to_period('Y')).sum()\n",
    "enoggera_yearly_df = enoggera_df.groupby(enoggera_df['Date'].dt.to_period('Y')).sum()\n",
    "ewen_maddock_yearly_df = ewen_maddock_df.groupby(ewen_maddock_df['Date'].dt.to_period('Y')).sum()\n",
    "gold_creek_yearly_df = gold_creek_df.groupby(gold_creek_df['Date'].dt.to_period('Y')).sum()\n",
    "hinze_yearly_df = hinze_df.groupby(hinze_df['Date'].dt.to_period('Y')).sum()\n",
    "lake_kurwongbah_yearly_df = lake_kurwongbah_df.groupby(lake_kurwongbah_df['Date'].dt.to_period('Y')).sum()\n",
    "lake_macdonald_yearly_df = lake_macdonald_df.groupby(lake_macdonald_df['Date'].dt.to_period('Y')).sum()\n",
    "lake_manchester_yearly_df = lake_manchester_df.groupby(lake_manchester_df['Date'].dt.to_period('Y')).sum()\n",
    "leslie_harrison_yearly_df = leslie_harrison_df.groupby(leslie_harrison_df['Date'].dt.to_period('Y')).sum()\n",
    "little_nerang_yearly_df = little_nerang_df.groupby(little_nerang_df['Date'].dt.to_period('Y')).sum()\n",
    "maroon_yearly_df = maroon_df.groupby(maroon_df['Date'].dt.to_period('Y')).sum()\n",
    "nindooinbah_yearly_df = nindooinbah_df.groupby(nindooinbah_df['Date'].dt.to_period('Y')).sum()\n",
    "north_pine_yearly_df = north_pine_df.groupby(north_pine_df['Date'].dt.to_period('Y')).sum()\n",
    "poona_yearly_df = poona_df.groupby(poona_df['Date'].dt.to_period('Y')).sum()\n",
    "seq_water_grid_yearly_df = seq_water_grid_df.groupby(seq_water_grid_df['Date'].dt.to_period('Y')).sum()\n",
    "somerset_yearly_df = somerset_df.groupby(somerset_df['Date'].dt.to_period('Y')).sum()\n",
    "wappa_yearly_df = wappa_df.groupby(wappa_df['Date'].dt.to_period('Y')).sum()\n",
    "wivenhoe_yearly_df = wivenhoe_df.groupby(wivenhoe_df['Date'].dt.to_period('Y')).sum()\n",
    "wyaralong_yearly_df = wyaralong_df.groupby(wyaralong_df['Date'].dt.to_period('Y')).sum()\n",
    "\n",
    "merged_dam_yearly_df = merged_dam_yearly_df.reset_index(drop=False)\n",
    "merged_dam_yearly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "9c236242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-410-1580473eab07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmerged_dam_monthly_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_dam_monthly_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0matkinson_monthly_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matkinson_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1M'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0matkinson_monthly_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matkinson_monthly_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%B'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0matkinson_monthly_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matkinson_monthly_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   6715\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6717\u001b[0;31m         return DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   6718\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6719\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    561\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;31m# a passed-in Grouper, directly convert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0mbinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(self, obj, validate)\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_grouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m         \u001b[0;31m# create the resampler and return our binner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_resampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_binner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/resample.py\u001b[0m in \u001b[0;36m_get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mTimedeltaIndexResampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   1477\u001b[0m             \u001b[0;34m\"Only valid with DatetimeIndex, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m             \u001b[0;34m\"TimedeltaIndex or PeriodIndex, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "# Group by month and calculate monthly totals\n",
    "\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "               'July', 'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "merged_dam_monthly_df = merged_dam_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "merged_dam_monthly_df.index = merged_dam_monthly_df.index.strftime('%B')\n",
    "merged_dam_monthly_df = merged_dam_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "merged_dam_monthly_df['Date'] = pd.Categorical(merged_dam_monthly_df['Date'], month_order)\n",
    "merged_dam_monthly_df = merged_dam_monthly_df.sort_values('Date')\n",
    "\n",
    "atkinson_monthly_df = atkinson_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "atkinson_monthly_df.index = atkinson_monthly_df.index.strftime('%B')\n",
    "atkinson_monthly_df = atkinson_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "atkinson_monthly_df['Date'] = pd.Categorical(atkinson_monthly_df['Date'], month_order)\n",
    "atkinson_monthly_df = atkinson_monthly_df.sort_values('Date')\n",
    "\n",
    "baroon_pocket_monthly_df = baroon_pocket_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "baroon_pocket_monthly_df.index = baroon_pocket_monthly_df.index.strftime('%B')\n",
    "baroon_pocket_monthly_df = baroon_pocket_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "baroon_pocket_monthly_df['Date'] = pd.Categorical(baroon_pocket_monthly_df['Date'], month_order)\n",
    "baroon_pocket_monthly_df = baroon_pocket_monthly_df.sort_values('Date')\n",
    "\n",
    "cedar_pocket_monthly_df = cedar_pocket_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "cedar_pocket_monthly_df.index = cedar_pocket_monthly_df.index.strftime('%B')\n",
    "cedar_pocket_monthly_df = cedar_pocket_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "cedar_pocket_monthly_df['Date'] = pd.Categorical(cedar_pocket_monthly_df['Date'], month_order)\n",
    "cedar_pocket_monthly_df = cedar_pocket_monthly_df.sort_values('Date')\n",
    "\n",
    "clarendon_monthly_df = clarendon_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "clarendon_monthly_df.index = clarendon_monthly_df.index.strftime('%B')\n",
    "clarendon_monthly_df = clarendon_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "clarendon_monthly_df['Date'] = pd.Categorical(clarendon_monthly_df['Date'], month_order)\n",
    "clarendon_monthly_df = clarendon_monthly_df.sort_values('Date')\n",
    "\n",
    "enoggera_monthly_df = enoggera_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "enoggera_monthly_df.index = enoggera_monthly_df.index.strftime('%B')\n",
    "enoggera_monthly_df = enoggera_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "enoggera_monthly_df['Date'] = pd.Categorical(enoggera_monthly_df['Date'], month_order)\n",
    "enoggera_monthly_df = enoggera_monthly_df.sort_values('Date')\n",
    "\n",
    "ewen_maddock_monthly_df = cooloolabin_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "ewen_maddock_monthly_df.index = cooloolabin_monthly_df.index.strftime('%B')\n",
    "ewen_maddock_monthly_df = cooloolabin_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "ewen_maddock_monthly_df['Date'] = pd.Categorical(ewen_maddock_monthly_df['Date'], month_order)\n",
    "ewen_maddock_monthly_df = cooloolabin_monthly_df.sort_values('Date')\n",
    "\n",
    "gold_creek_monthly_df = gold_creek_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "gold_creek_monthly_df.index = gold_creek_monthly_df.index.strftime('%B')\n",
    "gold_creek_monthly_df = gold_creek_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "gold_creek_monthly_df['Date'] = pd.Categorical(gold_creek_monthly_df['Date'], month_order)\n",
    "gold_creek_monthly_df = gold_creek_monthly_df.sort_values('Date')\n",
    "\n",
    "hinze_monthly_df = hinze_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "hinze_monthly_df.index = hinze_monthly_df.index.strftime('%B')\n",
    "hinze_monthly_df = hinze_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "hinze_monthly_df['Date'] = pd.Categorical(hinze_monthly_df['Date'], month_order)\n",
    "hinze_monthly_df = hinze_monthly_df.sort_values('Date')\n",
    "\n",
    "lake_kurwongbah_monthly_df = lake_kurwongbah_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "lake_kurwongbah_monthly_df.index = lake_kurwongbah_monthly_df.index.strftime('%B')\n",
    "lake_kurwongbah_monthly_df = lake_kurwongbah_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "lake_kurwongbah_monthly_df['Date'] = pd.Categorical(lake_kurwongbah_monthly_df['Date'], month_order)\n",
    "lake_kurwongbah_monthly_df = lake_kurwongbah_monthly_df.sort_values('Date')\n",
    "\n",
    "lake_macdonald_monthly_df = lake_macdonald_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "lake_macdonald_monthly_df.index = lake_macdonald_monthly_df.index.strftime('%B')\n",
    "lake_macdonald_monthly_df = lake_macdonald_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "lake_macdonald_monthly_df['Date'] = pd.Categorical(lake_macdonald_monthly_df['Date'], month_order)\n",
    "lake_macdonald_monthly_df = lake_macdonald_monthly_df.sort_values('Date')\n",
    "\n",
    "lake_manchester_monthly_df = lake_manchester_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "lake_manchester_monthly_df.index = lake_manchester_monthly_df.index.strftime('%B')\n",
    "lake_manchester_monthly_df = lake_manchester_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "lake_manchester_monthly_df['Date'] = pd.Categorical(lake_manchester_monthly_df['Date'], month_order)\n",
    "lake_manchester_monthly_df = lake_manchester_monthly_df.sort_values('Date')\n",
    "\n",
    "leslie_harrison_monthly_df = leslie_harrison_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "leslie_harrison_monthly_df.index = leslie_harrison_monthly_df.index.strftime('%B')\n",
    "leslie_harrison_monthly_df = leslie_harrison_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "leslie_harrison_monthly_df['Date'] = pd.Categorical(leslie_harrison_monthly_df['Date'], month_order)\n",
    "leslie_harrison_monthly_df = leslie_harrison_monthly_df.sort_values('Date')\n",
    "\n",
    "little_nerang_monthly_df = little_nerang_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "little_nerang_monthly_df.index = little_nerang_monthly_df.index.strftime('%B')\n",
    "little_nerang_monthly_df = little_nerang_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "little_nerang_monthly_df['Date'] = pd.Categorical(little_nerang_monthly_df['Date'], month_order)\n",
    "little_nerang_monthly_df = little_nerang_monthly_df.sort_values('Date')\n",
    "\n",
    "maroon_monthly_df = maroon_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "maroon_monthly_df.index = maroon_monthly_df.index.strftime('%B')\n",
    "maroon_monthly_df = lake_macdonald_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "maroon_monthly_df['Date'] = pd.Categorical(maroon_monthly_df['Date'], month_order)\n",
    "maroon_monthly_df = maroon_monthly_df.sort_values('Date')\n",
    "\n",
    "nindooinbah_monthly_df = nindooinbah_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "nindooinbah_monthly_df.index = nindooinbah_monthly_df.index.strftime('%B')\n",
    "nindooinbah_monthly_df = nindooinbah_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "nindooinbah_monthly_df['Date'] = pd.Categorical(nindooinbah_monthly_df['Date'], month_order)\n",
    "nindooinbah_monthly_df = nindooinbah_monthly_df.sort_values('Date')\n",
    "\n",
    "north_pine_monthly_df = north_pine_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "north_pine_monthly_df.index = north_pine_monthly_df.index.strftime('%B')\n",
    "north_pine_monthly_df = north_pine_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "north_pine_monthly_df['Date'] = pd.Categorical(north_pine_monthly_df['Date'], month_order)\n",
    "north_pine_monthly_df = north_pine_monthly_df.sort_values('Date')\n",
    "\n",
    "poona_monthly_df = poona_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "poona_monthly_df.index = poona_monthly_df.index.strftime('%B')\n",
    "poona_monthly_df = poona_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "poona_monthly_df['Date'] = pd.Categorical(poona_monthly_df['Date'], month_order)\n",
    "poona_monthly_df = poona_monthly_df.sort_values('Date')\n",
    "\n",
    "seq_water_grid_monthly_df = seq_water_grid_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "seq_water_grid_monthly_df.index = seq_water_grid_monthly_df.index.strftime('%B')\n",
    "seq_water_grid_monthly_df = seq_water_grid_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "seq_water_grid_monthly_df['Date'] = pd.Categorical(seq_water_grid_monthly_df['Date'], month_order)\n",
    "seq_water_grid_monthly_df = seq_water_grid_monthly_df.sort_values('Date')\n",
    "\n",
    "somerset_monthly_df = somerset_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "somerset_monthly_df.index = somerset_monthly_df.index.strftime('%B')\n",
    "somerset_monthly_df = somerset_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "somerset_monthly_df['Date'] = pd.Categorical(somerset_monthly_df['Date'], month_order)\n",
    "somerset_monthly_df = somerset_monthly_df.sort_values('Date')\n",
    "\n",
    "wappa_monthly_df = wappa_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "wappa_monthly_df.index = wappa_monthly_df.index.strftime('%B')\n",
    "wappa_monthly_df = wappa_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "wappa_monthly_df['Date'] = pd.Categorical(wappa_monthly_df['Date'], month_order)\n",
    "wappa_monthly_df = wappa_monthly_df.sort_values('Date')\n",
    "\n",
    "wyaralong_monthly_df = wyaralong_monthly_df.groupby(pd.Grouper(key='Date', freq='1M')).sum()\n",
    "wyaralong_monthly_df.index = wyaralong_monthly_df.index.strftime('%B')\n",
    "wyaralong_monthly_df = wyaralong_monthly_df.groupby(['Date']).sum().reset_index()\n",
    "wyaralong_monthly_df['Date'] = pd.Categorical(wyaralong_monthly_df['Date'], month_order)\n",
    "wyaralong_monthly_df = wyaralong_monthly_df.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "539b9f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef1ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate averages by decade"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
